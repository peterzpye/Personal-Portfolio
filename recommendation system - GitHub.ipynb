{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello everyone, this is a snapshot of what I did on the recommendation engine at DojoMojo/Innovation Department as a data science intern. I worked closely with our chief data scientist at my company on this and offered little help on algorithms. Note that this is not the final production code. This is only the draft that I worked on. The final production code is compiled with other algorithms created by the data scientist and I can not share it.\n",
    "\n",
    "\n",
    "Our business is a marketing partnership platform and our customers are all brands that want to seek marketing partnership. That being said, they could be both sellers and buyers.\n",
    "\n",
    "\n",
    "\n",
    "The recommendation system is a recommendation engine based on machine learning backed search space. It has two main logics: Content Based Filtering and Collaborative Based Filtering. The Content Based Filtering is based on the product similarity while Collaborative Based Filtering is based on user similarity.\n",
    "I created algorithms on both.\n",
    "\n",
    "\n",
    "The main search space for this collections of algorithms is KDTree as it provides quick search ability. Provided the large amount of data and limited resources we have our chief data scientist thought this was the best for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Based Filtering: Based on Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an algorithms inspired by LinkedIn connection features. Given the nature of our business, our customers are all businesses and they could be both customers and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Define the searching method\n",
    "# m is the brand_id to search for\n",
    "# n is # of neighbors we want to seek\n",
    "# mode has 3: overlap; all; unique\n",
    "def find_neighbors(m, n: int, mode:str): \n",
    "    if m != 0:\n",
    "        #tags\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        tag_data = mlb.fit_transform(space_population['tags'])\n",
    "        tags = pd.DataFrame(tag_data)\n",
    "\n",
    "        #numerical\n",
    "        numerical_data_unscaled = df2[['acquired', 'provided', \n",
    "                                       'dedicated_list_size','twitter_followers','facebook_followers', \n",
    "                                       'instagram_followers', 'pinterest_followers', \n",
    "                                       'average_sign_ups_per_campaign']]\n",
    "        numerical_data_unscaled = numerical_data_unscaled.fillna(numerical_data_unscaled.mean())\n",
    "        numerical_data_scaled = normalize(numerical_data_unscaled)\n",
    "        numerical = pd.DataFrame(numerical_data_scaled)\n",
    "        #merge\n",
    "        all_d = pd.concat((numerical, tags), axis = 1)\n",
    "        all_data = np.array(all_d)\n",
    "\n",
    "        #KDTree \n",
    "        numerical_space = cKDTree(numerical)\n",
    "        tags_space = cKDTree(tags)\n",
    "        all_space = cKDTree(all_d)\n",
    "\n",
    "        #finding the overlaped\n",
    "        idxs = []\n",
    "        idxs_rep = []\n",
    "        idxs_uniq = []\n",
    "        index = space_population.brand_id.index.get_loc(m)\n",
    "#       index = space_population['brand_id'][space_population['brand_id'] == m].index[0]\n",
    "        \n",
    "        #create a list of similar brand index and store it in different lists\n",
    "        values, idxs_a = all_space.query(all_data[index], k = n)    \n",
    "        for x in idxs_a:\n",
    "            if x in idxs:\n",
    "                if x not in idxs_rep:\n",
    "                    idxs_rep.append(x)\n",
    "                else:\n",
    "                    continue\n",
    "            idxs.append(x)\n",
    "\n",
    "        values, idxs_t = tags_space.query(tag_data[index], k = n)\n",
    "        for x in idxs_t:\n",
    "            if x in idxs:\n",
    "                if x not in idxs_rep:\n",
    "                    idxs_rep.append(x)\n",
    "                else:\n",
    "                    continue\n",
    "            idxs.append(x)\n",
    "\n",
    "        values, idxs_d = numerical_space.query(numerical_data_scaled[index], k = n)\n",
    "        for x in idxs_d:\n",
    "            if x in idxs:\n",
    "                if x not in idxs_rep:\n",
    "                    idxs_rep.append(x)\n",
    "                else:\n",
    "                    continue\n",
    "            idxs.append(x)\n",
    "\n",
    "        for x in idxs:\n",
    "            if x not in idxs_rep:\n",
    "                idxs_uniq.append(x)\n",
    "        \n",
    "        #returnning brand_index\n",
    "        if mode == 'overlap':\n",
    "            return idxs_rep\n",
    "        if mode == 'all':\n",
    "            return idxs\n",
    "        if mode == 'unique':\n",
    "            return idxs_uniq\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function for generating recommended list\n",
    "def recommend(brand_id:int, mode:str, quantity:int, df:pd.DataFrame):\n",
    "    lst = []\n",
    "    recommend_lst = []\n",
    "#     index = deal['brand_id'][deal['brand_id'] == brand_id].index\n",
    "    index = deal.brand_id.index.get_loc(brand_id)\n",
    "    #constructing full list by brand, 1st connection, 2nd connection\n",
    "    \n",
    "    a_list = find_neighbors(brand_id, n = quantity, mode = mode)\n",
    "    for x in a_list:\n",
    "        recommend_lst.append(x)\n",
    "\n",
    "# delete as we consider about past deals\n",
    "    b_list = find_neighbors(df.iloc[index, 1], n = quantity, mode = mode)\n",
    "    try:\n",
    "        for x in b_list:\n",
    "            recommend_lst.append(x)\n",
    "    except:\n",
    "        recommend_lst.append('none for 2nd connection')\n",
    "#     c_list = find_neighbors(df.iloc[ index, 2], n = quantity, mode = mode)\n",
    "#     try:\n",
    "#         for x in c_list:\n",
    "#             recommend_lst.append(x)\n",
    "#     except:\n",
    "#         recommend_lst.append('none for 3nd connection')\n",
    "    #find the unique value of recommended brand's index\n",
    "    for x in recommend_lst:\n",
    "        if x not in lst:\n",
    "            lst.append(x)\n",
    "    return lst[0: quantity]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Seller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a optional filter to check on brands who only sells. It is created as we need a clearer list of brands who are sure to sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 20\n",
      "dropped 11\n",
      "dropped 30\n",
      "dropped 36\n",
      "dropped 51\n",
      "dropped 71\n",
      "dropped 33\n",
      "dropped 4\n",
      "dropped 23\n",
      "dropped 9 elements as they are sellers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[52]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_seller(A: list, B:pd.DataFrame ):\n",
    "    count = 0\n",
    "    C = []\n",
    "    for x in A:\n",
    "        if x not in B.values:\n",
    "            print('dropped', x)\n",
    "            count += 1\n",
    "            continue\n",
    "        else:\n",
    "            C.append(x)\n",
    "        \n",
    "    print('dropped', count, 'elements as they have not been sellers')\n",
    "    return C\n",
    "\n",
    "\n",
    "buy_sell_info = pd.read_csv('buy_sell.csv')\n",
    "info = buy_sell_info['sell']\n",
    "\n",
    "check_seller(A, info)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>475</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2299</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>680</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2132</td>\n",
       "      <td>1516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_id  target\n",
       "0       475     305\n",
       "1      4646     305\n",
       "2      2299    1014\n",
       "3       680      52\n",
       "4      2132    1516"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal = pd.read_csv('deal.csv')\n",
    "deal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal.iloc[4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_id</th>\n",
       "      <th>dedicated_list_size</th>\n",
       "      <th>twitter_followers</th>\n",
       "      <th>facebook_followers</th>\n",
       "      <th>instagram_followers</th>\n",
       "      <th>pinterest_followers</th>\n",
       "      <th>average_sign_ups_per_campaign</th>\n",
       "      <th>acquired</th>\n",
       "      <th>provided</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2525</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6182</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>8150.75</td>\n",
       "      <td>1306.25</td>\n",
       "      <td>['Shopping', 'Apparel']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7235</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>702.50</td>\n",
       "      <td>16.00</td>\n",
       "      <td>['People &amp; Society', \"Women\\\\'s Health\", 'Heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7762</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7369</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_id  dedicated_list_size  twitter_followers  facebook_followers  \\\n",
       "0      2525                  100                  0                   0   \n",
       "1      6182               100000                  0                   0   \n",
       "2      7235                 3000                  0                   0   \n",
       "3      7762                60000                  0                   0   \n",
       "4      7369                   10                  0                   0   \n",
       "\n",
       "   instagram_followers  pinterest_followers  average_sign_ups_per_campaign  \\\n",
       "0                    0                    0                         1210.0   \n",
       "1                    0                    0                         1264.0   \n",
       "2                    0                    0                           16.0   \n",
       "3                    0                    0                            0.0   \n",
       "4                    0                    0                            0.0   \n",
       "\n",
       "   acquired  provided                                               tags  \n",
       "0       NaN       NaN                                                NaN  \n",
       "1   8150.75   1306.25                            ['Shopping', 'Apparel']  \n",
       "2    702.50     16.00  ['People & Society', \"Women\\\\'s Health\", 'Heal...  \n",
       "3       NaN       NaN                                                NaN  \n",
       "4       NaN       NaN                                                NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#brand connection space\n",
    "brand_1st_connection = pd.read_csv('brand_1st_connection.csv')\n",
    "brand_2nd_connection = pd.read_csv('brand_2nd_connection.csv')\n",
    "brand_connection = pd.merge(brand_1st_connection, brand_2nd_connection, on = 'brand', how = 'outer')\n",
    "brand_connection.columns = ['brand_id', '1st_conn', '2nd_conn']\n",
    "brand_connection_1 = pd.merge(space_population[['brand_id']], brand_connection, on = 'brand_id', how = 'left')\n",
    "\n",
    "df1 = pd.read_csv('cluster_user.csv')\n",
    "df1.columns = ['brand_id','dedicated_list_size','twitter_followers','facebook_followers', 'instagram_followers', 'pinterest_followers', 'average_sign_ups_per_campaign']\n",
    "df1.fillna(0,inplace = True)\n",
    "space_population = pd.read_csv('space_population.csv')\n",
    "df2 = pd.merge(df1, space_population[['brand_id', 'acquired','provided', 'tags']], on = 'brand_id', how = 'left')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = recommend(11, quantity = 15, mode = 'overlap', df = deal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Below was an analysis on how to imporve the recommendation at that time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few points for improvement:\n",
    "1. based on past deal instead of similar brands: change neighbor objects to its past seller        DONE\n",
    "2. put in more metrics in finding the neighbors        Working\n",
    "\n",
    "3. no sellers to sellers\n",
    "\n",
    "4. feedback mechanism based on competitors: not sure how to do yet\n",
    "possible solution: \n",
    "\n",
    "    a. competitor brand prediction \n",
    "\n",
    "    b. reinforcement learning on recommendation choices \n",
    "\n",
    "    c. give choice of competitors to user and drop that option from then on\n",
    "\n",
    "5. no seller to seller: \n",
    "Thinking on the solutions:\n",
    "\n",
    "    a. based on current profile, Set up a Boolean column  DONE\n",
    "\n",
    "    b. for buyer/seller mixers, find metrics for probability or find cluster on sell and buy objects\n",
    "\n",
    "    c. buyer/seller prediction\n",
    "\n",
    "6. recent tag only\n",
    "7. additional metrics: price/budget\n",
    "\n",
    "\n",
    "Current problem: \n",
    "1. finding more metrics\n",
    "    reason: limited in data: need to derive more metrics\n",
    "\n",
    "2. feedback mechanism: not sure what to do yet\n",
    "\n",
    "3. no seller to seller: should be able to solve as long as with solid logic\n",
    "\n",
    "4. industry tag: currently most industry tags missing: working on google description NLP project/ Parsing Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Based Filtering: email matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since email list is such an important feature to our clients, in this algorithm, I analyzed on brands' email lists, and calculated the similarity based on email matching rate."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this algo, the logic is the below:\n",
    "1. recommend based on the email similarity and dissimilarity:\n",
    "    a. the emails should be different(to be discussed)\n",
    "    b. the emails should be in similar region\n",
    "    c. the emails gender distribution should be similar\n",
    "    d. the emails age distribution\n",
    "    e. tag the emails\n",
    "    \n",
    "2. recommend should be filtered by the following:\n",
    "    a. competitors --------- wait for discuss\n",
    "    b. buyers to buyers (discuss); b to s; s to b; sellers to sellers BIG NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_data = pd.read_csv('email_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>industry</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>email_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2174</td>\n",
       "      <td>Beauty &amp; Care</td>\n",
       "      <td>1020</td>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>Beauty &amp; Care</td>\n",
       "      <td>2666</td>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2174</td>\n",
       "      <td>Beauty &amp; Care</td>\n",
       "      <td>2664</td>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2174</td>\n",
       "      <td>Beauty &amp; Care</td>\n",
       "      <td>2563</td>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2174</td>\n",
       "      <td>Beauty &amp; Care</td>\n",
       "      <td>2360</td>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       industry  brand_id  email_id  gender   age  longitude  latitude\n",
       "0  2174  Beauty & Care      1020      2246       0  66.0    -97.822    37.751\n",
       "1  2174  Beauty & Care      2666      2246       0  66.0    -97.822    37.751\n",
       "2  2174  Beauty & Care      2664      2246       0  66.0    -97.822    37.751\n",
       "3  2174  Beauty & Care      2563      2246       0  66.0    -97.822    37.751\n",
       "4  2174  Beauty & Care      2360      2246       0  66.0    -97.822    37.751"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "num_data = email_data[['age', 'longitude', 'latitude']]\n",
    "industry_data = email_data[['industry']]\n",
    "num_data['gender_encoded'] = email_data['gender'].apply(lambda x: 0 if x == 'male' else 1)\n",
    "data = normalize(num_data)\n",
    "\n",
    "\n",
    "# was doing encoder but the data size too huge to operate\n",
    "# encode = OneHotEncoder()\n",
    "# etag_data = encode.fit_transform(tag_data).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "brand_id = 2\n",
    "\n",
    "n_num = 10\n",
    "r_num = 20\n",
    "index_lst = email_data[email_data['brand_id']==brand_id].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding the neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 9 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 10 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 6 recommends\n",
      "not enough data, returning 9 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n",
      "not enough data, returning 7 recommends\n"
     ]
    }
   ],
   "source": [
    "recommend_lst = []\n",
    "# creating search space\n",
    "search_space = cKDTree(data)\n",
    "for index in index_lst:\n",
    "    values, idxs_a = search_space.query(data[index], k = n_num)\n",
    "    df = pd.DataFrame(email_data['brand_id'][idxs_a])\n",
    "    count = df.groupby(email_data['brand_id']).count()\n",
    "    count.columns = ['count']\n",
    "    count.sort_values('count', ascending = False, inplace = True)\n",
    "    r_lst = []\n",
    "    lst = np.ndarray.tolist(count.index.values)\n",
    "    if r_num <= len(lst):\n",
    "        r_lst = lst[0:r_num]\n",
    "    else: \n",
    "        r_lst = lst\n",
    "        print('not enough data, returning', len(lst), 'recommends')\n",
    "    recommend_lst += r_lst\n",
    "\n",
    "\n",
    "# find the unique value\n",
    "recommend_index = []\n",
    "\n",
    "\n",
    "for x in recommend_lst:\n",
    "    if x not in recommend_index:\n",
    "        recommend_index.append(x)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 15,\n",
       " 22,\n",
       " 29,\n",
       " 49,\n",
       " 100,\n",
       " 183,\n",
       " 228,\n",
       " 234,\n",
       " 348,\n",
       " 359,\n",
       " 362,\n",
       " 430,\n",
       " 481,\n",
       " 509,\n",
       " 515,\n",
       " 535,\n",
       " 648,\n",
       " 890,\n",
       " 940,\n",
       " 1002,\n",
       " 1048,\n",
       " 1137,\n",
       " 1142,\n",
       " 1257,\n",
       " 1275,\n",
       " 1815,\n",
       " 2436]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(recommend_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_data = email_data['industry'][index_lst]\n",
    "industry_data = industry_data.values.tolist()\n",
    "industry_opt = []\n",
    "for x in industry_data:\n",
    "    if x not in industry_opt:\n",
    "        industry_opt.append(x)\n",
    "        \n",
    "# filtering out the ones of different industries\n",
    "# this is not yet the final logic, the final one was done with a apriori analysis chart \n",
    "# on closely related industries. \n",
    "recommend_industry_filtered = []\n",
    "for y in recommend_index:\n",
    "    if email_data['industry'][y] in industry_opt:\n",
    "        recommend_industry_filtered.append(y)\n",
    "recommend_industry_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beauty & Care', 'Media', 'eCommerce', 'Retail'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(email_data['industry'][recommend_lst]).industry.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Media              29949\n",
       "eCommerce          16645\n",
       "Beauty & Care      16570\n",
       "Retail              9094\n",
       "Travel & Trans.     8780\n",
       "Fashion             6228\n",
       "Home & Garden       5734\n",
       "Food & Bev.         3259\n",
       "Education           2862\n",
       "Entertainment        357\n",
       "Daily Deals          291\n",
       "Electronics          168\n",
       "Health & Fit          63\n",
       "Name: industry, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyzing on industries of the emails\n",
    "email_data['industry'][recommend_lst].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter through brand identity(no sellers to sellers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 2664\n",
      "dropped 2666\n",
      "dropped 2563\n",
      "dropped 515\n",
      "dropped 430\n",
      "dropped 362\n",
      "dropped 2456\n",
      "dropped 1257\n",
      "dropped 1137\n",
      "dropped 1894\n",
      "dropped 1002\n",
      "dropped 2281\n",
      "dropped 1894\n",
      "dropped 2369\n",
      "dropped 2281\n",
      "dropped 1142\n",
      "dropped 2369\n",
      "dropped 1257\n",
      "dropped 1976\n",
      "dropped 1257\n",
      "dropped 2281\n",
      "dropped 1894\n",
      "dropped 362\n",
      "dropped 2281\n",
      "dropped 1257\n",
      "dropped 1976\n",
      "dropped 362\n",
      "dropped 1257\n",
      "dropped 1137\n",
      "dropped 2666\n",
      "dropped 1988\n",
      "dropped 1096\n",
      "dropped 2369\n",
      "dropped 2456\n",
      "dropped 1002\n",
      "dropped 1988\n",
      "dropped 1002\n",
      "dropped 1849\n",
      "dropped 2666\n",
      "dropped 39 elements as they have not been sellers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2436, 481, 43, 2436, 1571, 481, 481, 2436, 2440, 43, 1571]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_seller(A: list):\n",
    "    buy_sell_info = pd.read_csv('buy_sell.csv')\n",
    "    B = buy_sell_info['sell']\n",
    "    count = 0\n",
    "    C = []\n",
    "    for x in A:\n",
    "        if x not in B.values:\n",
    "            print('dropped', x)\n",
    "            count += 1\n",
    "            continue\n",
    "        else:\n",
    "            C.append(x)\n",
    "        \n",
    "    print('dropped', count, 'elements as they have not been sellers')\n",
    "    return C\n",
    "\n",
    "recommend_value = email_data['brand_id'][recommend_index]\n",
    "A = email_data\n",
    "check_seller(recommend_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
